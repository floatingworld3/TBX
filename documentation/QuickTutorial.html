<!DOCTYPE html>
<html>

<head>
  <link rel="stylesheet" href="home.css">
  <link rel="stylesheet" href="home1.css">


</head>



<div id="parent">
  <div id="side">
    <nav class="toc">
      <h2 id="tbx-header">
        TBX v 2 User Guide
      </h2>
      <ul>
        <li><a href="home.html">Introduction</a>
          <ul>
            <li id="mark"><a href="home.html#arkit">ARKit Face Tracking with iPhone</a></li>
            <li id="mark"><a href="home.html#features">Features of TBX</a></li>
            <li id="mark"><a href="home.html#licensing">Licensing</a></li>
            <li id="mark"><a href="home.html#installation">Installation</a></li>
          </ul>


        </li>
        <li>
          <a href="#qiuckTutorial">Quick Tutorial</a>
          <ul>
            <li id="mark"><a href="#step1">Step 1 - Creating CSV Tracking files</a></li>
            <li id="mark"><a href="#step2">Step 2 - Real Time Performance capture</a></li>
            <li id="mark"><a href="#step3">Step 3 - Importing Tracking Data into TBX</a></li>
            <li id="mark"><a href="#step4">Step 4 - Extracting audio and image sequence from a clip</a></li>
            <li id="mark"><a href="#step5">Step 5 - Converting to FBX</a></li>
            <li id="mark"><a href="#step6">Step 6 - Exporting your FBX file</a></li>
            <li id="mark"><a href="#step7">Step 7 - Using FBX to animate rigs</a></li>
          </ul>
        </li>
        <li>
          <a href="VideoTutorial.html#videoTutorial">Video Tutorial</a>
          <ul>
            <li id="mark"><a href="VideoTutorial.html#vid">Creating FBX files from Tracking Data for Facial
                Animation</a></li>

          </ul>
        </li>
        <li>
          <a href="AndySerkis.html#1">Gallery</a>
          <ul>
            <li id="mark"><a href="AndySerkis.html#1">Sample performance capture using Andy Serkis reciting a
                Shakespeare soliloquy</a></li>
            <li id="mark"><a href="PerfYoutube.html#2">Sample of Performance capture from youtube video (no revision or
                editing)</a></li>
            <li id="mark"><a href="lip.html#3">Newsreader lip sync capture</a></li>
          </ul>
        </li>
        <li>
          <a href="Downloads.html#downloads">Downloads</a>
          <ul>
            <li id="mark"><a href="Downloads.html#down">Sample News Reader CSV file and resultant FBX file from sample
                video</a></li>

          </ul>
        </li>
        <li>
          <a href="BPractice.html#bpractice">Best Practice when capturing performances</a>
          <ul>
            <li id="mark"><a href="BPractice.html#step2">Set up</a></li>

          </ul>
        </li>
        <li style="padding-bottom: 40px;">
          <a href="FutureVersions.html#future">Future Versions</a>
          <ul>
            <li id="mark"><a href="FutureVersions.html#fversions">Additional features</a></li>

          </ul>
        </li>
      </ul>
      <svg class="toc-marker" width="200" height="200" xmlns="http://www.w3.org/2000/svg">
        <path stroke="#444" stroke-width="3" fill="transparent" stroke-dasharray="0, 0, 0, 1000" stroke-linecap="round"
          stroke-linejoin="round" transform="translate(-0.5, -0.5)" />
      </svg>
    </nav>
  </div>

  <div id="main" style="">
    <div id="quickTutorial">


      <br>
      <div id="step1">
        <div class=" pr-5 pl-5">
          <h3 class="h3">Creating CSV Tracking files
          </h3>
          <p class="wrapper-dark">
            Go to the video section of www.RigVadar.com and load any video.
            This can be an mp4 or QT or almost any other format.
          </p>

          <a href="assets/RigVadar_Interface.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/RigVadar_Interface.jpg" style="max-width: 90%; height:auto;"></a>
          <br>
          <p class="wrapper-dark">
            <li class="wrapper-dark">You can select which portion of the clip you want tracked by selecting the 'from'
              and 'to' frame numbers on the right.</li><br>
            <li class="wrapper-dark"> Make sure the displayed frame rate value matches the video frame rate.</li><br>
            <li class="wrapper-dark"> Reference frame can be selected here as well, which will be recorded in the
              metadata of the generated CSV file.</li><br>
            <li class="wrapper-dark">This will be a neutral face pose which serves as a starting point for deviations
              from neutral pose which can be a metric for expressions. </li><br>
            <li class="wrapper-dark">This is so a file can be produced of deviations from the reference frame which
              translates as relative movement.</li><br>
            <li class="wrapper-dark">A CSV file can be produced containing just these deviations from neutral which
              compresses the data further.</li><br>

            <li class="wrapper-dark">If you require additional points to be tracked, simply point and click on the video
              and name the point to be tracked.
              Select the tracking parameters (number of levels,patch size, iterations), which have an accuracy/speed
              tradeoff. Press 'ANALYZE' and the tracking occurs as the video plays in almost real time.</li>
          </p>
          <a href="assets/trackerextrapoint.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/trackerextrapoint.jpg" style="max-width: 90%; height:auto;"></a>
          <p class="wrapper-dark">
            After tracking is completed, press the 'DOWNLOAD COORDINATES' button.
          </p>
          <a href="assets/trackextrapt2.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/trackextrapt2.jpg" style="max-width: 90%; height:auto;"></a>
          <p class="wrapper-dark">
            Save the csv file to desired location. The CSV file is human-readable and can be inspected using any
            spreadsheet program such as Excel.
          </p>
          <a href="assets/spreadsheet.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/spreadsheet.jpg" style="max-width: 90%; height:auto;"></a>
          <p class="wrapper-dark">
            The position data for each tracked point appears, along with scale, rotation and mask movement data.
          </p>
          <p class="wrapper-dark">
            Alternatively, you can choose the 'folder' section of the rigvadar site, which uses a folder of images. This
            might be useful if you have larger files to deal with.
          </p>
          <a href="assets/folder_tab.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/folder_tab.jpg" style="max-width: 90%; height:auto;"></a>
          <p class="wrapper-dark">
            Select a folder which contains the image set you require. Or you could also select 'convert video file to a
            set of images'....in this case, it's the Data folder containing the newsreader footage...
          </p>
          <a href="assets/Folder_pick.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/Folder_pick.jpg" style="max-width: 90%; height:auto;"></a>
          <p class="wrapper-dark">
            Click on a frame you wish to serve as the reference frame then press 'analyze' as before...
          </p>
          <a href="assets/Analyze_foldert.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/Analyze_foldert.jpg" style="max-width: 90%; height:auto;"></a>
          <p class="wrapper-dark">
            The csv file will be produced as before.
          </p>
        </div>
      </div>
      <div id="step2">
        <div class=" pr-5 pl-5">
          <h3 class="h3"> Real Time Performance capture
          </h3>
          <p class="wrapper-dark">
            If real time performance capture is important to your studio, the RT component can be downloaded from the
            RigVadar site at reasonable cost.
          </p>
          <p class="wrapper-dark">
            You may then navigate to the Live A/V section of the RigVadar site.
          </p>
          <p class="wrapper-dark">
            You will be prompted to mute your speaker. Otherwise annoying feedback will occur.
          </p>
          <a href="assets/liveAV.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/liveAV.jpg" style="max-width: 90%; height:auto;"></a>

          <p class="wrapper-dark">
            <li class="wrapper-dark">Press 'connect' to connect to the RT component, then set up a camera feed.</li><br>
            <li class="wrapper-dark"> Press 'record and tracking', and the CSV file will be written as the subject
              performs in real time. </li><br>
            <li class="wrapper-dark"> Press 'stop' and the CSV file becomes immediately available for download, along
              with the video record of the performance.</li><br>
            <li class="wrapper-dark">It will be possible to set up real time connection with rigs in other applications
              such as Maya 3ds Max and Unreal.</li><br>
            <li class="wrapper-dark">Contact RigVadar technical support if you require this feature.</li><br>

          </p>

        </div>
      </div>
      <div id="step3">
        <div>
          <h3 class="h3">Importing Tracking Data into TBX
          </h3>
          <p class="wrapper-dark">Open TBX and navigate to the CSV file location.
          </p>
          <a href="assets/files.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/files.jpg" style="max-width: 90%; height:auto;"></a>
          <ul class="wrapper-dark">
            <li class="wrapper-dark pr-5">You may at this time include the audio file if you have it, otherwise you may
              use the 'extract' function of TBX to extract both the image set as well as the audio track.</li>
            <li class="wrapper-dark pr-5">The output location can be chosed. If no location is chosen ,the generated FBX
              file will be imported by default into the same folder as the CSV file.</li>

          </ul>
          <p class="wrapper-dark">The frame rate of the CSV file along with the range of frame numbers will appear in
            the input boxes:</p>
          <a href="assets/Range.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/Range.jpg" style="max-width: 90%; height:auto;"></a><br><br>

          <li class="wrapper-dark pr-5">It is possible to change the start and end frames to achieve a simple edit.</li>
          <br>
          <li class="wrapper-dark pr-5">Frames either side will be static. This is useful for layered animation from
            different takes.</li><br>
          <li class="wrapper-dark pr-5">All the FBX markers are parented to a Root marker ( dummy or null).</li><br>
          <li class="wrapper-dark pr-5">This makes it easy to move the set around in your chosen application.</li> <br>
          <li class="wrapper-dark pr-5">The name of this root will be the same as the name of the CSV file.</li> <br>
          <li class="wrapper-dark pr-5">You may at this time choose to change the size (scale) of the root marker as
            well as the other markers in the FBX file. </li> <br>
          <li class="wrapper-dark pr-5"> The local orientation of the root can also be changed before export.</li> <br>
          <li class="wrapper-dark pr-5"> This will of course radically change the postion and orientation of all the
            linked markers.</li> <br>
          <li class="wrapper-dark pr-5"> This will depend on the particular application you will be working with.</li>
          <br>
          <a href="assets/mask.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/mask.jpg" style="max-width: 90%;  height:auto;"></a><br><br>
          <li class="wrapper-dark pr-5">'Apply Position' when checked will use the mass movement of the mask (the set of
            facial markers linked to the root marker which is part of the CSV capture data), to animate the root.</li>
          <br>
          <li class="wrapper-dark pr-5">This is not always what we want when doing facial animation but the option is
            there if, for example , we want to do a face swap in a video.</li><br>
          <li class="wrapper-dark pr-5">The marker prefix is useful in creating a set of markers with a prefix in order
            to distinguish them from another set , as the markers all have generic names and this may cause conflicts in
            the application into which they are imported.</li><br>
          <li class="wrapper-dark pr-5">The local orientation of the markers is very important when linking them to
            control splines, as their axis vectors must align with those of the splines for correct movement.</li> <br>
          <li class="wrapper-dark pr-5"> Place 180 in the local Rotation X input box for example, to have the x axis of
            the markers pointing in the opposite direction.</li> <br>
          <p class="wrapper-dark"> Up Vector selection and frame rate:</p>
          <a href="assets/scene.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/scene.jpg" style="max-width: 90%; height:auto;"></a><br>
          <p class="wrapper-dark">The up vector will be chosen dependant on the application you will import it into.</p>
        </div>
      </div>
      <div id="step4">
        <div class=" pr-5 pl-5">
          <h3 class="h3">Extracting audio and image sequence from a clip
          </h3>
          <p class="wrapper-dark">If you wish to extract the audio from the source clip, you can do so here, along with
            the set of images from the clip:
          </p>
          <a href="assets/conversion.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/conversion.jpg" style="max-width: 90%; height:auto;"></a><br>
          <p class="wrapper-dark">
            You can choose to extract just the audio or just the image set, or neither.
            The frame set and audio will be placed in the same location as the CSV file.
            The audio file will be automatically placed in the input for audio, and will become part of the generated
            FBX file.
          </p>

        </div>
      </div>
      <div id="step5">
        <div class=" pr-5 pl-5">
          <h3 class="h3">Converting to FBX
          </h3>
          <p class="wrapper-dark">Now you are ready to generate the FBX file by pressing the 'Convert FBX' button.
          </p>
          <a href="assets/conversion.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/conversion.jpg" style="max-width: 90%; height:auto;"></a><br>
          <p class="wrapper-dark">
            This will produce a file in the same folder as the CSV file, or at the location specified in the output
            requester.
            This usually takes only a few seconds.
          </p>

        </div>
      </div>
      <div id="step6">
        <div class=" pr-5 pl-5">
          <h3 class="h3"> Exporting your FBX file
          </h3>
          <p class="wrapper-dark">The FBX file can now be exported to many 3d application such as Maya, 3ds max, Blender
            etc.
          </p>
          <p class="wrapper-dark">
            The FBX file audio track can be read by all except 3ds max, which requires the user to give the location of
            the audio file, which you can do by navigating to the original folder containing the FBX file.

          </p>

        </div>
      </div>
      <div id="step7">
        <div class=" pr-5 pl-5">
          <h3 class="h3">Using FBX to animate rigs
          </h3>
          <p class="wrapper-dark">The FBX file is essentially an animation of major facial landmark features, and can be
            used to connect facial performance data to any rig in any 3d program.
          </p>
          <p class="wrapper-dark">
            In the case of 3ds max, we connect the major controls to dummies which move as the relative distance between
            two markers in the FBX file. For example, the difference between the chin and nose moves the mouth control
            and reflects mouth open/closed.
          </p>
          <p class="wrapper-dark">
            Note that since these controls move many adjacent points on the face, the need for many morphs and countless
            control splines vanishes.
          </p>
          <p class="wrapper-dark">
            In this case, each master control on the rig can control 9 morph targets, so that each of the 5 controls
            around the mouth can , potentially, control 45 morph targets with only a few movements.
          </p>
          <p class="wrapper-dark">
            In the example below , there are no morph targets at all, as it is all bone(muscle) based. However this can
            easily be converted into a morph based rig.
          </p>
          <p class="wrapper-dark">
            This rig was built in a matter of a few minutes using the RigVadar rigging software for 3ds max.
          </p>
          <p class="wrapper-dark">
            It also makes possible the rapid design of any rigging UI, with connections to either objects, morph targets
            or custom attributes such as wrinkle maps for procedural animation of almost any parameter via one control
            only.
          </p>
          <p class="wrapper-dark">
            Similar rigs can be built for Maya using MEL scripts.
          </p>
          <a href="assets/max.jpg" target="_blank" style="display: flex; justify-content: center;"><img
              src="assets/max.jpg" style="max-width: 90%; height:auto;"></a><br>
        </div>
      </div>
    </div>



    </body>
    <script>
      var toc = document.querySelector('.toc');
      var tocPath = document.querySelector('.toc-marker path');
      var tocItems;
      // Factor of screen size that the element must cross
      // before it's considered visible
      var TOP_MARGIN = 0.1,
        BOTTOM_MARGIN = 0.2;
      var pathLength;
      var lastPathStart,
        lastPathEnd;
      window.addEventListener('resize', drawPath, false);
      window.addEventListener('scroll', sync, false);
      drawPath();
      function drawPath() {
        tocItems = [].slice.call(toc.querySelectorAll('li'));
        // Cache element references and measurements
        tocItems = tocItems.map(function (item) {
          var anchor = item.querySelector('a');
          var target = document.getElementById(anchor.getAttribute('href').slice(1));
          return {
            listItem: item,
            anchor: anchor,
            target: target
          };
        });
        // Remove missing targets
        tocItems = tocItems.filter(function (item) {
          return !!item.target;
        });
        var path = [];
        var pathIndent;
        tocItems.forEach(function (item, i) {
          var x = item.anchor.offsetLeft - 5,
            y = item.anchor.offsetTop,
            height = item.anchor.offsetHeight;
          if (i === 0) {
            path.push('M', x, y, 'L', x, y + height);
            item.pathStart = 0;
          }
          else {
            // Draw an additional line when there's a change in
            // indent levels
            if (pathIndent !== x) path.push('L', pathIndent, y);
            path.push('L', x, y);
            // Set the current path so that we can measure it
            tocPath.setAttribute('d', path.join(' '));
            item.pathStart = tocPath.getTotalLength() || 0;
            path.push('L', x, y + height);
          }
          pathIndent = x;
          tocPath.setAttribute('d', path.join(' '));
          item.pathEnd = tocPath.getTotalLength();
        });
        pathLength = tocPath.getTotalLength();
        sync();
      }
      function sync() {
        var windowHeight = window.innerHeight;
        var pathStart = pathLength,
          pathEnd = 0;
        var visibleItems = 0;
        tocItems.forEach(function (item) {
          var targetBounds = item.target.getBoundingClientRect();
          if (targetBounds.bottom > windowHeight * TOP_MARGIN && targetBounds.top < windowHeight * (1 - BOTTOM_MARGIN)) {
            pathStart = Math.min(item.pathStart, pathStart);
            pathEnd = Math.max(item.pathEnd, pathEnd);
            visibleItems += 1;
            item.listItem.classList.add('visible');
          }
          else {
            item.listItem.classList.remove('visible');
          }
        });
        // Specify the visible path or hide the path altogether
        // if there are no visible items
        if (visibleItems > 0 && pathStart < pathEnd) {
          if (pathStart !== lastPathStart || pathEnd !== lastPathEnd) {
            tocPath.setAttribute('stroke-dashoffset', '1');
            tocPath.setAttribute('stroke-dasharray', '1, ' + pathStart + ', ' + (pathEnd - pathStart) + ', ' + pathLength);
            tocPath.setAttribute('opacity', 1);
          }
        }
        else {
          tocPath.setAttribute('opacity', 0);
        }
        lastPathStart = pathStart;
        lastPathEnd = pathEnd;
      }
    </script>

</html>